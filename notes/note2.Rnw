\documentclass[10pt]{beamer}

\usepackage{graphicx, color}
\usepackage{alltt}
\usepackage{booktabs, calc, rotating}
\usepackage[round]{natbib}
\usepackage{pdfpages, subfigure}
\usepackage{multicol}
\usepackage{amsmath, amsbsy, amssymb, amsthm, graphicx}
\usepackage[english]{babel}
\usepackage{xkeyval} 
\usepackage{xfrac}
\usepackage{multicol}
\usepackage[normalem]{ulem}
\usepackage{multirow, fancyvrb} 
\usepackage{tikz, geometry, tkz-graph, xcolor}
\usepackage{listings}

\let\oldemptyset\emptyset
\let\emptyset\varnothing

\renewenvironment{knitrout}{\setlength{\topsep}{-.2mm}}{}

\usetikzlibrary{arrows,positioning} 
\tikzset{
  % Define standard arrow tip
  >=stealth',
  % Define style for boxes
  punkt/.style={
    rectangle,
    rounded corners,
    draw=black, very thick,
    text width=6.5em,
    minimum height=2em,
    text centered},
  % Define arrow style
  pil/.style={
    ->,
    thick,
    shorten <=2pt,
    shorten >=2pt,}
}
\usetikzlibrary{trees}
% Set the overall layout of the tree
\tikzstyle{level 1}=[level distance=2.5cm, sibling distance=4cm] 
\tikzstyle{level 2}=[level distance=2.5cm, sibling distance=2.5cm]
\tikzstyle{level 3}=[level distance=2.5cm, sibling distance=1cm]

% Define styles for bags and leafs
\tikzstyle{bag} = [text width=4em, text centered]
\tikzstyle{end} = [circle, minimum width=3pt,fill, inner sep=0pt]
\tikzstyle{openend} = [circle, minimum width=3pt, inner sep=0pt]

\hypersetup{colorlinks, citecolor=blue, linkcolor=., menucolor=white, filecolor=blue, anchorcolor=yellow}

\usetikzlibrary{arrows,positioning} 
\tikzset{
  % Define standard arrow tip
  >=stealth',
  % Define style for boxes
  punkt/.style={rectangle, rounded corners, draw=black, very thick, text width=6.5em, 
    minimum height=2em, text centered},
  % Define arrow style
  pil/.style={ ->, thick, shorten <=2pt, shorten >=2pt,}}

\graphicspath{{figure/}}

\newcommand{\cov}{\mathrm{cov}}
\newcommand{\dif}{\mathrm{d}}
\newcommand{\bigbrk}{\vspace*{2in}}
\newcommand{\smallbrk}{\vspace*{.1in}}
\newcommand{\midbrk}{\vspace*{1in}}
\newcommand{\red}[1]{{\color{red}#1}}
\newcommand{\empr}[1]{{\emph{\color{red}#1}}}
\newcommand{\blue}[1]{{\color{blue}#1}}
\newcommand{\green}[1]{{\color{green}#1}}
\newcommand{\pkg}[1]{{\textbf{\texttt{#1}}}}
\newcommand{\code}[1]{{\texttt{#1}}}
\newcommand{\calc}[1]{{\fbox{\mbox{#1}}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\var}{\mathrm{var}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\p}{\mathrm{P}}
\newcommand{\Skm}{\widehat{S}_{\scriptsize{KM}}}
\newcommand{\Sna}{\widehat{S}_{\scriptsize{NA}}}
\newcommand{\Hkm}{\widehat{H}_{\scriptsize{KM}}}
\newcommand{\Hna}{\widehat{H}_{\scriptsize{NA}}}
\newcommand{\V}{\mathrm{V}}
\newcommand{\R}{\texttt{R}}
\newcommand{\Cov}{\mathrm{Cov}}

\mode<presentation> {
  \usetheme{UTD}
  \usecolortheme[RGB={200,0,0}]{structure}
  \setbeamercovered{transparent}
}

\usepackage[latin1]{inputenc}
\usepackage{times}
\usepackage[T1]{fontenc}

\DeclareSymbolFont{extraup}{U}{zavm}{m}{n}
\DeclareMathSymbol{\varheart}{\mathalpha}{extraup}{86}
\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}

\newcommand*{\mybox}[1]{\framebox{#1}}

\title[STAT 6390]{STAT 6390: Analysis of Survival Data\\
  \small{Textbook coverage: Chapter 2}\\}
\author[Steven Chiou]{Steven Chiou}
\institute[UTD]{Department of Mathematical Sciences, \\ University of Texas at Dallas}
\date{}

% UTD logo on top right corner
% \usepackage[absolute, overlay]{textpos}
% \addtobeamertemplate{frametitle}{}{%
% \begin{textblock*}{100cm}(.94\textwidth, 0.6cm)
%   \includegraphics[trim = 1.8cm .9cm 1.8cm .92cm, clip, scale = .28, keepaspectratio]{UTDlogo}
% \end{textblock*}}

\begin{document}

\begin{frame}[fragile]
  \titlepage
<< setup, echo= FALSE, results='asis'>>=
knitr::opts_chunk$set(fig.path = "figure/", prompt = TRUE, comment = NA, size = "scriptsize")
@ 
\end{frame}

\setbeamercolor*{item}{fg=red}
\bgroup
\usebackgroundtemplate{%
  \tikz[overlay,remember picture] \node[opacity=0.05, at=(current page.center)] {
    \includegraphics[height=\paperheight,width=\paperwidth]{UTDbg}};}

\section{Survivor, hazard and cumulative hazard functions}
\begin{frame}[fragile]
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
  \item Suppose the actual (uncensored, untruncated) survival time of an individual is $t$
    and can be regarded as the observed value of a variable, $T$.
  \item We assume the support of $T$ is non-negative or $(0, \infty)$.
  \item We call $T$ the \emph{random variable} associated with the survival time, 
    and we define $T$ has a cumulative distribution function given by
    $F(t) = \p(T \le t)$.
  \item The survival function of $T$ is then defined as $$S(t) = 1 - \p(T\le t) = 1 - F(t).$$
  \item Why are we more interested in $S(t)$?
  \end{itemize}
  <<library, echo = FALSE, message = FALSE>>=
  library(tidyverse)
  @

\end{frame}

\begin{frame}
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
    \item The \empr{hazard function} is widely used to survival analysis. 
    \item The hazard function $h(t)$ is defined below
      \begin{equation}
        h(t) = \lim_{\delta\to0}\frac{\p(t\le T < t + \delta|T\ge t)}{\delta}.
        \label{eq:haz}
      \end{equation}
    \item $\p(t\le T< t + \delta|T\ge t)$ is a conditional probability.
      %the probability $T$ lies between $t$ and $t + \delta$ \emph{condition on} $T \ge t$.
    \item The conditional probability is then expressed as a probability per nit time by dividing by the time interval, $\delta$, to give a \emph{rate}.
    \item The function $h(t)$ is also referred to as the \empr{hazard rate}, the \empr{instantaneous death rate}, 
      the \empr{intensity rate}, or the \empr{force of mortality}.
    \item Event rate at time $t$, conditional on the event not having occurred before $t$.
    \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
    \item In terms of probability, if $t$ is measured in days, $h(t)$ is the approximate probability that an individual, 
      who is \emph{at risk} of the event occurring at the start of day $t$, experiences the event during that day.
      \begin{itemize}
      \item In this case $\delta = 1$.
      \item $\lim_{\delta \to0}$ can be thought of as changing the unit from days to hours, minutes, seconds, milliseconds...
      \end{itemize}
    \item If the event of interest is not death, $h(t)$ can also be regarded as the \emph{expected number of events}
      experienced by an individual in unit time, given that the event has not occurred before then. 
      \begin{itemize}
        \item Think of $\E\{\I(\cdot)\} = \p(\cdot)$.
        \item The part ``given that the event...'' might be ignored if events follow the Poisson process.
        \end{itemize}
      \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
    \item The definition in~\eqref{eq:haz} leads to some useful relationships between survivor and hazard functions:
      \begin{equation*}
        \hspace{-.5cm}
        (1) = \lim_{\delta\to0}\frac{\p(t\le T < t + \delta)}{\delta\cdot\p(T < t)} = 
        \lim_{\delta\to0}\frac{F(t + \delta) - F(t)}{\delta} \cdot \frac{1}{\p(T < t)} =
        \frac{\dif F(t)}{\dif t}\cdot \frac{1}{S(t)}.
      \end{equation*}
    \item $h(t)$ is approximately the probability that an individual experiences an event at this instant ($t$)
      given that he/she is risk free up to $t$.
    \item If $T$ is a continuous random variable, then we have 
      \begin{equation}
        h(t) = \frac{f(t)}{S(t)}.
        \label{eq:haz2}
      \end{equation}
    \item This shows that from any one of the three functions, $f(t)$, $S(t)$, and $h(t)$, 
      the other two can be determined. 
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
    \item Equation~\eqref{eq:haz2} also implies
      $$h(t) = -\frac{\dif}{\dif t}\left\{ \log S(t)\right\} \mbox{ and } S(t) = e^{-H(t)},$$
      where $H(t) = \int_0^th(u)\,\dif u$ is the \empr{cumulative hazard function}.
    \item Similarly, the cumulative hazard function can also be obtained from 
      $$H(t) = -\log S(t).$$
    \item The cumulative hazard function is the cumulative risk of an event occurring by time $t$.
    \item If the event is death, then $H(t)$ summarizes the risk of death up to time $t$, given that death has not occurred by $t$.
    \item If the event is not death, $H(t)$ can be interpreted as the expected number of events that occur in the interval $(0, t)$.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Survivor, hazard and cumulative hazard functions}
  \begin{itemize}
    \item It is possible for $H(t) > 1$, $h(t) > 1$, or $f(t) > 1$.
    \item Like $F(t)$, $S(t)$ is bounded in $[0, 1]$.
    \item $F(t)$ and $H(t)$ is non-decreasing; $S(t)$ is non-increasing.
    \item $h(t)$ can go up and down.
    \item For example, suppose $T\sim\exp(\lambda)$, where $\lambda$ is the rate. Then
      \begin{itemize}
      \item $S(t) = e^{-\lambda t}$.
      \item $h(t) = \lambda$.
      \item $H(t) = \lambda t$.
  \end{itemize}
\end{itemize}
\end{frame}

\section{Estimating $S(t)$}

\begin{frame}
  \frametitle{Empirical survivor function}
  \begin{itemize}
  \item The $S(t)$ can be estimated non-parametrically with the \empr{product limit} estimator, 
    which is also known as the \empr{Kaplan-Meier} estimator.
  \item We first assume there is a single sample of survival times, 
    and none of these are censored. 
  \item In this case, the survivor probability at $t$, $S(t)$, is defined as 
    \begin{equation}
      \hat S_e(t) = \frac{\mbox{\# individuals with survival times} \ge t}{\mbox{\# individuals in the data set}}.
        \label{eq:empS}
    \end{equation}
  \item Equation~\eqref{eq:empS} is called \empr{empirical survivor function}. 
  \item Similar $\hat F_e(t) = 1 - \hat S_e(t)$ is called the \empr{empirical cumulative distribution function}.
    \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Empirical survivor function}
  \begin{itemize}
  \item We illustrate with the first 10 uncensored subjects in the \texttt{whas100} data.
  \item Make sure \pkg{tidyverse} package and \code{whas100} are properly loaded*.
  <<install, echo = FALSE>>=
  load("whas100.RData")
  whas100 <- as.tibble(whas100)
  @
  <<subset-whas>>=
  whas10 <- whas100 %>% filter(fstat > 0) %>% filter(row_number() <= 10)
  whas10 
  @
\end{itemize}
\hfill\tiny* see note 1 for details.
\end{frame}

\begin{frame}[fragile]
  \frametitle{Empirical survivor function}
  \begin{itemize}
  \item The empirical estimates can be easily computed with \code{ecdf}.
  \end{itemize}
  <<ecdf>>=
  whas10 <- whas10 %>% mutate(surv = 1 - ecdf(lenfol)(lenfol))
  whas10
  @
\end{frame}

\begin{frame}[fragile]
  \frametitle{Empirical survivor function}
  \begin{itemize}
  \item The empirical survivor function is a non-increasing step function.
  \end{itemize}
  <<ecdf-plot, eval = FALSE>>=
  whas20 %>% ggplot(aes(lenfol, surv)) + geom_step(size = 1.2)
  @
  \begin{center}
    \includegraphics[scale = .3]{whas10-ecdf}
  \end{center}
  \begin{itemize}
  \item The $\hat S_e(t)$ is 1 at $t = 0$ and 0 at the final death time. %, $\max(t)$.
  \item The $\hat S_e(t)$ is assumed to be constant between adjacent death times.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Empirical survivor function}
  \begin{itemize}
  \item Putting everything together, we could plot the empirical survival curve for all the uncensored subjects in \code{whas100}:
  \end{itemize}
  <<ecdf-plot2, eval = FALSE>>=
  whas100 %>% filter(fstat > 0) %>% mutate(surv = 1 - ecdf(lenfol)(lenfol)) %>%
      ggplot(aes(lenfol, surv)) + geom_step() + geom_smooth()
  @
  \begin{center}
    \includegraphics[scale = .3]{whas100-ecdf}
  \end{center} \vspace{-.3cm}
  \begin{itemize}
  \item The pipeline between \code{ggplot} is ``$+$'' instead of ``\code{\%>\%}''.
  \end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Kaplan-Meier estiamtor}
  \begin{itemize}
  \item With censoring, the same idea can be applied with proper adjustment.
  \item Kaplan-Meier estimator is the default estimator used by many packages. 
  \item The basic idea is to decompose $\p(T > t)$ by conditioning on prior times.
  \item Suppose a sample size of $n$, $\p(T>t)$ can be decomposed as
    {\scriptsize
    \begin{equation*}
      \Skm(t) \doteq   \p(T > t) = 
      \p(T > t_{(0)}) \cdot \p(T > t_{(1)} | T > t_{(0)}) \cdot \p(T > t_{(2)} | T > t_{(1)}) 
      \cdot\ldots\cdot \p(T > t | T > t_{(i)}),
    \end{equation*}}
    for a series of time intervals $0 \doteq  t_{(0)} < t_{(1)} < \ldots < t_{(i)} < t$ for some $i\le n$.
  \item In general, the series $\{t_{(1)}, \ldots, t_{(m)}\}$ 
    denotes the $m$ ordered death times.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Kaplan-Meier estiamtor}
  Suppose we want $\p(T > 800)$ among the first 20 patients in \texttt{whas1000}.
  \begin{columns}
    \column{0.45\textwidth}
    \includegraphics[scale = .3]{tab1-1-4}
    \column{0.55\textwidth}
    \begin{itemize}
    \item There are 6 events before $t = 800$.
    \item The events occured at 
      {\scriptsize
      \begin{tabular}{lllllll}
        $t_{(0)}$ & $t_{(1)}$ & $t_{(2)}$ & $t_{(3)}$ & $t_{(4)}$ & $t_{(5)}$ & $t_{(6)}$ \\
        \midrule
        0 & 6 & 98 & 189 & 302 & 374 & 492 \\
      \end{tabular}}
    \end{itemize}
  \end{columns}
  \vspace{-.3cm}
  {\scriptsize
  \begin{align*}
    \Skm(800) &= \p(T > 800) =\\
    &= \p(T > 0) \times \p(T > 6|T > 0) \times \p(T > 98|T > 6) \times
    \ldots\times \p(T > 492|T > 374) \\
    &=1 \times \frac{19}{20} \times \frac{18}{19} \times \frac{17}{18} \times \frac{16}{17} \times \frac{15}{16} \times 
    \frac{14}{15} = \frac{14}{20} = 70\%
  \end{align*}
  }
  Why does $\Skm(800) = \hat S_e(800)$ here?
\end{frame}

\begin{frame}[fragile]
  \frametitle{Kaplan-Meier estimator}
  \begin{itemize}
  \item The Kaplan-Meier estimator can be obtained with the \code{survfit} function.
    % from \pkg{survival}.
    <<survfit>>=
    library(survival)
    km <- survfit(Surv(lenfol, fstat) ~ 1, data = whas100, subset = id <= 20)
    summary(km)
    @
  \end{itemize}    
\end{frame}

\begin{frame}[fragile]
  \frametitle{Kaplan-Meier estimator}
  \begin{itemize}
  \item The Kaplan-Meier curve can be plotted with \code{plot} or \code{ggsurvplot}.
    <<survfit-plot, eval = FALSE>>=
    library(survminer)
    plot(km)
    ggsurvplot(km)
    @
    \includegraphics[scale = .28]{km1}\hspace{.2cm}
    \includegraphics[scale = .28]{km2}
  \item Since \pkg{survminer} depends on the newest version of \pkg{survMisc},
    you might need to update the latter to be able to use \code{ggsurvplot}.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Kaplan-Meier estimator}
  Suppose we want $\p(T > 800)$ based on the following modified data:
  \begin{columns}
    \column{0.45\textwidth}
    \includegraphics[scale = .3]{tab1-1-5}
    \column{0.55\textwidth}
    \begin{itemize}
    \item There are 3 events before $t = 800$.
    \item The events occured at 
      {\scriptsize
      \begin{tabular}{lllllll}
        $t_{(0)}$ & $t_{(1)}$ & $t_{(2)}$ & $t_{(3)}$ \\
        \midrule
        0 & 6 & 374 & 492 \\
      \end{tabular}}
    \item In this modified data, $t = 98, 189, 302$ are considered as censored.
    \end{itemize}
  \end{columns}
  \vspace{-.3cm}
  {\scriptsize
  \begin{align*}
    \Skm(800) &= \p(T > 800) =\\
    &= \p(T > 0) \times \p(T > 6|T > 0) \times \p(T > 374|T > 6) \times \p(T > 492|T > 374) \\
    &=1 \times \frac{19}{20} \times \frac{15}{16} \times \frac{14}{15} \approx 83.1\%
  \end{align*}
  }
\end{frame}

\begin{frame}[fragile]
  \frametitle{Kaplan-Meier estimator}
  \begin{itemize}
  \item The Kaplan-Meier estimator for the whole data is
    <<survfit-whole, eval = FALSE>>=
    library(survival)
    km <- survfit(Surv(lenfol, fstat) ~ 1, data = whas100)
    plot(km)
    ggsurvplot(km)    
    @    
    \includegraphics[scale = .28]{km3}\hspace{.2cm}
    \includegraphics[scale = .28]{km4}
  \item If the last observed time corresponds to a censored observation, 
    then the estimate of the survival function does not go to zero.
  \end{itemize}    
\end{frame}


\begin{frame}
  \frametitle{Kaplan-Meier estimator}
  \begin{itemize}
  \item Suppose we have a sample of $n$ independent observations $(t_i, c_i), i = 1, 2, \ldots, n$.
  \item There are $m$ deaths and $m\le n$.
  \item The series $\{t_{(1)}, \ldots, t_{(m)}\}$ are the $m$ ordered death times.
  \item The Kaplan-Meier estimator has the form
    \begin{equation*}
      \Skm(t) = \prod_{t_{(i)} \le t}\frac{n_i - d_i}{n_i} = \prod_{t_{(i)} \le t} 1 - \frac{d_i}{n_i},
    \end{equation*}
    where $n_i$ is the number of individual who are alive at $t_{(i)}$ (at risk),
    and $d_i$ is the number of individual who died at $t_{(i)}$.
  \item A potential problem with the Kaplan-Meier estimator is when $n_i$ is small and
    $n_i = d_i$ occurs at early time.
  \end{itemize}    
\end{frame}

\begin{frame}
  \frametitle{Nelson-Aalon estimator}
  \begin{itemize}
  \item An alternative estimate of $\Skm(t)$ is the \empr{Nelson-Aalon estimator}:
    \begin{equation*}
      \Sna(t) = \prod_{t_{(i)} \le t} \exp\left(-\frac{d_i}{n_i}\right).
    \end{equation*}
  \item The main idea is to see $d_i/n_i$ as the event rate, i.e., $h(t_{(i)}) = d_i/n_i$.
  \item Recall the relationship $h(t) = f(t) / S(t)$ and think of $d_i/n$ and $n_i/n$ 
    are raw rough estimates of $f(t)$ and $S(t)$.
  \item By the similar argument, we have
    $$\Hna(t) \doteq H(t) = \sum_{t_{(i)} \le t} d_i/n_i, \mbox{ and } S(t) = e^{-\Hna(t)} = \Sna(t).$$
  \item $\Sna(t)$ and $\Skm(t)$ are derived differently, but both based on $d_i$ and $n_i$.
  \item In general $\Sna(t)\ge\Skm(t)$ but $\Sna(t)\approx\Skm(t)$.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Nelson-Aalon estimator}
  \begin{itemize}
  \item $\Sna(t)$ has slightly nicer properties and is more stable.
  \item If the interest is in estimating the cumulative hazard function, $H(t)$, 
    we can use either the $\Hna(t)$, or $\Hkm = -\log(\Skm(t))$.
  \item $\Sna(t)$ can be obtained with \code{coxph} of the \pkg{survival} package.
    <<NA-est>>=
    args(coxph)
    @
  \item \code{coxph} refers to ``Cox proportional hazard model'' that has the form
    \begin{equation}
      h(t) = h_0(t) e^{X^\top\beta}, 
      \label{eq:cox}
    \end{equation}
    where $X$ is the covariate matrix, $\beta$ is the regression coefficient, 
    and $h_0(t)$ is called the \emph{baseline hazard} function.
  \item More details will be given in Chapter 3. 
  \end{itemize}
\end{frame}


\begin{frame}[fragile]
  \frametitle{Nelson-Aalon estimator}
  \begin{itemize}
  \item For now, we will assume $\beta = 0$ in~\eqref{eq:cox}, which implies $h(t) = h_0(t)$.
  \item We will use $h_0(t)$ to obtain $\Sna(t)$.
    <<coxph-NA>>=
    cox <- coxph(Surv(lenfol, fstat) ~ 1, data = whas100)
    H0 <- basehaz(cox)
    str(H0)
    @
    <<coxph-NA2, eval = FALSE>>=
    plot(km)
    lines(H0$time, exp(-H0$hazard), 's', col = 2)
    @
    \begin{center}
      \includegraphics[scale = .25, trim = 1cm 1.6cm 1cm 2cm, clip]{km5}
    \end{center}
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Life-table estimates}
  \begin{itemize}
  \item When dataset is large, the $\Skm(t)$ and $\Sna(t)$ can be obtained with intervals of time, 
    rather than exact time points.
    \begin{itemize}
    \item The series $\{t_{(1)}, \ldots, t_{(m)}\}$ represents intervals. 
    \item $d_i$ represents the number of individual who died in $t_{(i)}$.
    \item $n_i$ represents the number of individual who are alive in $t_{(i)}$.
    \end{itemize}
  \item Potential problem with censoring? 
  \item Adjustments under uniform assumption (p25).
\end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Inference on $\Skm(t)$}
  \begin{itemize}
    \item The 95\% confidence interval does not follow the usual form of 
      $$\mbox{PE} \pm 1.96 \times\mbox{SE}.$$
    \item This is mainly because $\Skm(t)$ lies between 0 and 1. 
    \item Two common methods to obtain the 95\% confidence interval for $\Skm(t)$ are the
      $\log$ and $\log$-$\log$ transformations.
    \item The idea is to derive the standard errors on the transformed scale first, 
      then back-transform these back.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{The Delta Method}
  \begin{itemize}
    \item We need the Delta method to estimate the standard errors.
    \item The Delta method states that
      $$ \Var\{f(X)\}\approx \Var(X) \cdot\{f^\prime(x_0)\}^2,$$
      where $f^\prime(x_0)$ is the 1st derivative of $f(\cdot)$ evaluates at constant $x_0$.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{The Delta Method}
  \begin{itemize}
    \item A special case of the Delta method is when $f(\cdot) = \log(\cdot)$.
    \item Setting $f(\cdot) = \log(\cdot)$, we have
      $$ \Var\{f(X)\}\approx \frac{\Var(X)}{x_0^2}.$$
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Inference on $\Skm(t)$}
  \begin{itemize}
    \item We will first look at the $\log$ transformation.
    \item Recall $$\Skm(t) = \prod_{t_{(i)}\le t}\frac{n_i - d_i}{n_i}.$$
    \item The variance of $\log$-transformed $\Skm(t)$ gives
       $$\Var\left[\log\left\{\Skm(t)\right\}\right] = \Var\left\{\sum_{t_{(i)}\le t}\log\left(\frac{n_i - d_i}{n_i}\right)\right\} = 
       \sum_{t_{(i)}\le t}\Var\left\{\log\left(\frac{n_i - d_i}{n_i}\right)\right\}.$$
     \item We assume independence between observations in the risk sets.
     \item For convenience, let's write $p_i = (n_i - d_i) / n_i$, and $\hat p_i$ when $n_i$ and $d_i$ are known.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Inference on $\Skm(t)$}
  \begin{itemize}
  \item The key is to estimate $\Var\left\{\log\left(p_i\right)\right\}$ with the Delta method.
  \item For each $t_{(i)}$, $n_i$ is a fixed constant $d_i$ is random. 
  \item $n_i - d_i$ is the risk set size and can be assumed to follow the binomial distribution with parameters $n_i$ and $1 - d_i / n_i$.
    Then
    \begin{align*}
      % \E(p_i) &= \frac{\E(n_i - d_i)}{n_i} = 1 - \frac{d_i}{n_i}, \\
      \Var(p_i) &= \frac{\Var(n_i - d_i)}{n_i^2} = \frac{\frac{d_i}{n_i}\cdot\left(1 - \frac{d_i}{n_i}\right)}{n_i}.
    \end{align*}
  \item With the Delta method, we have
    % $$ \Var\{\log(p_i)\} \approx \frac{\Var(p_i)}{\E^2(p_i)} = \frac{d_i}{n_i\cdot(n_i-d_i)}. $$
    $$ \Var\{\log(p_i)\} \approx \frac{\Var(p_i)}{\hat p_i} = \frac{d_i}{n_i\cdot(n_i-d_i)}. $$
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Inference on $\Skm(t)$}
  \begin{itemize}
  \item From the above result, we have
    $$\Var\left[\log\{\Skm(t)\}\right] \approx \sum_{t_{(i)}\le t}\frac{d_i}{n_i\cdot(n_i-d_i)}. $$
  \item By the Delta method, 
    $$\Var\left[\log\{\Skm(t)\}\right] \approx \Var\{\Skm(t)\} \cdot \frac{1}{\Skm^2(t)}.$$ 
  \item Altogether, this gives
    $$ \Var\{\Skm(t)\} \approx \Skm^2(t)\cdot\sum_{t_{(i)}\le t}\frac{d_i}{n_i\cdot(n_i-d_i)}.$$
  \item This result is known as the \emph{Greenwood's formula}.
  \item This estimator can be obtained from a counting process approach.
  \end{itemize}
\end{frame}


\begin{frame}
  \frametitle{Inference on $\Skm(t)$}
  \begin{itemize}
  \item With the Greenwood formula, the condifdence interval of $\Skm(t)$ can be obtained using the usual form of $\mbox{PE}\pm Z_{\alpha/2}\times\mbox{SE}$.
  \item The bounds can still be outside of $[0, 1]$.
  \end{itemize}
\end{frame}


\end{document}


